{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a07a343",
      "metadata": {
        "id": "7a07a343"
      },
      "source": [
        "\n",
        "\n",
        "### **Description:**  \n",
        "The dataset contains images of cats and dogs labeled for classification purposes. Each image belongs to one of the two classes: 'Cat' or 'Dog'. The goal is to classify the images correctly based on the content (i.e., whether the image is of a cat or a dog). The dataset is often used to test image classification models.\n",
        "\n",
        "**Note: The model was not trained during GPU constraints.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "Eo27O-xh2gxd"
      },
      "id": "Eo27O-xh2gxd",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb0fc5ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb0fc5ee",
        "outputId": "7b189200-e6cf-4602-cc53-4dc44fe01494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 24980, done.\u001b[K\n",
            "remote: Total 24980 (delta 0), reused 0 (delta 0), pack-reused 24980 (from 1)\u001b[K\n",
            "Receiving objects: 100% (24980/24980), 783.68 MiB | 24.13 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Updating files: 100% (50007/50007), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/haya60/datasets.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the Data"
      ],
      "metadata": {
        "id": "jdcoyBtP89DL"
      },
      "id": "jdcoyBtP89DL"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "dataset_dir = '/content/datasets/PetImages'\n",
        "categories = ['Dog', 'Cat']\n",
        "\n",
        "# Create directories for train, validation, and test sets\n",
        "base_dir = '/content/datasets/split_data'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "for category in categories:\n",
        "    os.makedirs(os.path.join(base_dir, 'train', category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, 'val', category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, 'test', category), exist_ok=True)\n",
        "\n",
        "\n",
        "def split_data(category):\n",
        "    category_dir = os.path.join(dataset_dir, category)\n",
        "    images = os.listdir(category_dir)\n",
        "\n",
        "    train_imgs, test_imgs = train_test_split(images, test_size=0.30, random_state=42)\n",
        "    val_imgs, test_imgs = train_test_split(test_imgs, test_size=0.50, random_state=42)\n",
        "\n",
        "    for img in train_imgs:\n",
        "        shutil.copy(os.path.join(category_dir, img), os.path.join(base_dir, 'train', category, img))\n",
        "    for img in val_imgs:\n",
        "        shutil.copy(os.path.join(category_dir, img), os.path.join(base_dir, 'val', category, img))\n",
        "    for img in test_imgs:\n",
        "        shutil.copy(os.path.join(category_dir, img), os.path.join(base_dir, 'test', category, img))\n",
        "\n",
        "for category in categories:\n",
        "    split_data(category)\n",
        "\n",
        "print(\"Data successfully split into train, validation, and test sets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJCoKpud6-DU",
        "outputId": "95427f55-0949-47e3-ae82-9061cef11fd3"
      },
      "id": "kJCoKpud6-DU",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully split into train, validation, and test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb05577",
      "metadata": {
        "id": "3cb05577"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/datasets/split_data/train'\n",
        "test_dir = '/content/datasets/split_data/test'\n",
        "valid_dir = '/content/datasets/split_data/val'\n",
        "\n",
        "img_size = (200, 200)\n",
        "batch_size = 128\n",
        "\n",
        "# train\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# test\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# valid\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = next(train_generator)\n",
        "X_test, y_test = next(test_generator)\n",
        "X_valid, y_valid = next(valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uknpko4A9JFY",
        "outputId": "3e826589-9faa-4a6d-ee64-18583dbf45db"
      },
      "id": "Uknpko4A9JFY",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17498 images belonging to 2 classes.\n",
            "Found 3752 images belonging to 2 classes.\n",
            "Found 3750 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3ce960",
      "metadata": {
        "id": "fc3ce960"
      },
      "source": [
        "## Building the CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca1a1cb",
      "metadata": {
        "id": "2ca1a1cb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "91a5150c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91a5150c",
        "outputId": "1f5d5047-8178-4d44-ae16-179f23ca7a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(200, 200, 3)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(254, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(254, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0fff4b8",
      "metadata": {
        "id": "e0fff4b8"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e11ddcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e11ddcd",
        "outputId": "d3451f51-d1ee-448b-dd3f-fe35416ffb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator , batch_size=200, epochs=20, validation_data=valid_generator, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba878f4",
      "metadata": {
        "id": "3ba878f4"
      },
      "source": [
        "## Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd3a753",
      "metadata": {
        "id": "5cd3a753"
      },
      "outputs": [],
      "source": [
        "model.evaluate(valid_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e0c1b9",
      "metadata": {
        "id": "93e0c1b9"
      },
      "source": [
        "## Testing with New Images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db94a8ae",
      "metadata": {
        "id": "db94a8ae"
      },
      "source": [
        "Finally, let's test the model with some new images. Preprocess the images and use the trained model to predict whether the image is of a cat or a dog.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf379ec",
      "metadata": {
        "id": "1cf379ec"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}